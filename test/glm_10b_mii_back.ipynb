{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append('./glm_10b_chinese')\n",
    "\n",
    "import torch\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import deepspeed\n",
    "\n",
    "from modeling_glm import GLMForConditionalGeneration\n",
    "from modeling_glm import GLMBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"BAAI/glm-10b-chinese\", trust_remote_code=True)\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(\"BAAI/glm-10b\", trust_remote_code=True)\n",
    "# model.load_state_dict(torch.load('./blocklm-10b-chinese/mp_rank_00_model_states.pt'),strict=False)\n",
    "# model = GLMForConditionalGeneration.from_pretrained('glm_10b_chinese')\n",
    "model = GLMForConditionalGeneration.from_pretrained('models/character_20230102_1055')\n",
    "model = model.half().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLMForConditionalGeneration(\n",
      "  (glm): GLMModel(\n",
      "    (word_embeddings): VocabEmbedding()\n",
      "    (transformer): GLMStack(\n",
      "      (embedding_dropout): Dropout(p=0.1, inplace=False)\n",
      "      (position_embeddings): Embedding(1025, 4096)\n",
      "      (block_position_embeddings): Embedding(1025, 4096)\n",
      "      (layers): ModuleList(\n",
      "        (0): GLMBlock(\n",
      "          (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention): SelfAttention(\n",
      "            (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
      "            (attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "            (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): GLMBlock(\n",
      "          (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention): SelfAttention(\n",
      "            (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
      "            (attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "            (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): GLMBlock(\n",
      "          (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention): SelfAttention(\n",
      "            (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
      "            (attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "            (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): GLMBlock(\n",
      "          (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention): SelfAttention(\n",
      "            (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
      "            (attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "            (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): GLMBlock(\n",
      "          (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention): SelfAttention(\n",
      "            (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
      "            (attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "            (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): GLMBlock(\n",
      "          (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention): SelfAttention(\n",
      "            (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
      "            (attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "            (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): GLMBlock(\n",
      "          (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention): SelfAttention(\n",
      "            (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
      "            (attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "            (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): GLMBlock(\n",
      "          (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention): SelfAttention(\n",
      "            (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
      "            (attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "            (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): GLMBlock(\n",
      "          (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention): SelfAttention(\n",
      "            (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
      "            (attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "            (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): GLMBlock(\n",
      "          (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention): SelfAttention(\n",
      "            (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
      "            (attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "            (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): GLMBlock(\n",
      "          (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention): SelfAttention(\n",
      "            (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
      "            (attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "            (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): GLMBlock(\n",
      "          (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention): SelfAttention(\n",
      "            (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
      "            (attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "            (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (12): GLMBlock(\n",
      "          (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention): SelfAttention(\n",
      "            (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
      "            (attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "            (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (13): GLMBlock(\n",
      "          (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention): SelfAttention(\n",
      "            (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
      "            (attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "            (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (14): GLMBlock(\n",
      "          (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention): SelfAttention(\n",
      "            (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
      "            (attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "            (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (15): GLMBlock(\n",
      "          (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention): SelfAttention(\n",
      "            (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
      "            (attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "            (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (16): GLMBlock(\n",
      "          (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention): SelfAttention(\n",
      "            (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
      "            (attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "            (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (17): GLMBlock(\n",
      "          (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention): SelfAttention(\n",
      "            (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
      "            (attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "            (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (18): GLMBlock(\n",
      "          (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention): SelfAttention(\n",
      "            (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
      "            (attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "            (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (19): GLMBlock(\n",
      "          (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention): SelfAttention(\n",
      "            (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
      "            (attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "            (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (20): GLMBlock(\n",
      "          (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention): SelfAttention(\n",
      "            (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
      "            (attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "            (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (21): GLMBlock(\n",
      "          (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention): SelfAttention(\n",
      "            (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
      "            (attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "            (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (22): GLMBlock(\n",
      "          (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention): SelfAttention(\n",
      "            (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
      "            (attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "            (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (23): GLMBlock(\n",
      "          (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention): SelfAttention(\n",
      "            (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
      "            (attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "            (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (24): GLMBlock(\n",
      "          (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention): SelfAttention(\n",
      "            (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
      "            (attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "            (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (25): GLMBlock(\n",
      "          (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention): SelfAttention(\n",
      "            (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
      "            (attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "            (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (26): GLMBlock(\n",
      "          (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention): SelfAttention(\n",
      "            (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
      "            (attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "            (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (27): GLMBlock(\n",
      "          (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention): SelfAttention(\n",
      "            (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
      "            (attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "            (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (28): GLMBlock(\n",
      "          (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention): SelfAttention(\n",
      "            (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
      "            (attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "            (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (29): GLMBlock(\n",
      "          (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention): SelfAttention(\n",
      "            (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
      "            (attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "            (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (30): GLMBlock(\n",
      "          (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention): SelfAttention(\n",
      "            (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
      "            (attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "            (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (31): GLMBlock(\n",
      "          (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention): SelfAttention(\n",
      "            (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
      "            (attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "            (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (32): GLMBlock(\n",
      "          (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention): SelfAttention(\n",
      "            (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
      "            (attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "            (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (33): GLMBlock(\n",
      "          (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention): SelfAttention(\n",
      "            (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
      "            (attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "            (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (34): GLMBlock(\n",
      "          (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention): SelfAttention(\n",
      "            (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
      "            (attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "            (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (35): GLMBlock(\n",
      "          (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention): SelfAttention(\n",
      "            (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
      "            (attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "            (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (36): GLMBlock(\n",
      "          (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention): SelfAttention(\n",
      "            (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
      "            (attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "            (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (37): GLMBlock(\n",
      "          (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention): SelfAttention(\n",
      "            (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
      "            (attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "            (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (38): GLMBlock(\n",
      "          (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention): SelfAttention(\n",
      "            (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
      "            (attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "            (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (39): GLMBlock(\n",
      "          (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention): SelfAttention(\n",
      "            (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
      "            (attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "            (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (40): GLMBlock(\n",
      "          (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention): SelfAttention(\n",
      "            (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
      "            (attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "            (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (41): GLMBlock(\n",
      "          (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention): SelfAttention(\n",
      "            (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
      "            (attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "            (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (42): GLMBlock(\n",
      "          (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention): SelfAttention(\n",
      "            (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
      "            (attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "            (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (43): GLMBlock(\n",
      "          (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention): SelfAttention(\n",
      "            (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
      "            (attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "            (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (44): GLMBlock(\n",
      "          (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention): SelfAttention(\n",
      "            (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
      "            (attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "            (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (45): GLMBlock(\n",
      "          (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention): SelfAttention(\n",
      "            (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
      "            (attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "            (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (46): GLMBlock(\n",
      "          (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention): SelfAttention(\n",
      "            (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
      "            (attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "            (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (47): GLMBlock(\n",
      "          (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (attention): SelfAttention(\n",
      "            (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
      "            (attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "            (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (final_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepspeed.utils.logger.setLevel('INFO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-02-08 19:32:20,730] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.8.0, git-hash=unknown, git-branch=unknown\n",
      "[2023-02-08 19:32:20,732] [WARNING] [config_utils.py:67:_process_deprecated_field] Config parameter mp_size is deprecated use tensor_parallel.tp_size instead\n",
      "[2023-02-08 19:32:20,732] [INFO] [logging.py:68:log_dist] [Rank 0] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1\n"
     ]
    }
   ],
   "source": [
    "# Initialize the DeepSpeed-Inference engine\n",
    "ds_engine = deepspeed.init_inference(model,\n",
    "                                 mp_size=1,\n",
    "                                 dtype=torch.half,\n",
    "                                #  checkpoint=None,\n",
    "                                #  replace_method='auto',\n",
    "                                #  replace_with_kernel_inject=True\n",
    "                                 injection_policy={GLMBlock: ('SelfAttention.o', 'DenseReluDense.wo')},\n",
    "                                 enable_cuda_graph=True,\n",
    "                                 \n",
    "                                 )\n",
    "model = ds_engine.module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(text, max_length=32):\n",
    "    if '[gMASK]' in text:\n",
    "        mask_id = tokenizer.gmask_token_id\n",
    "    elif '[MASK]' in text:\n",
    "        mask_id = tokenizer.mask_token_id\n",
    "    elif '[sMASK]' in text:\n",
    "        mask_id = tokenizer.smask_token_id\n",
    "    else:\n",
    "        text += '[gMASK]'\n",
    "        mask_id = tokenizer.gmask_token_id\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    print(inputs)\n",
    "\n",
    "    inputs = tokenizer.build_inputs_for_generation(inputs, max_gen_length=512)\n",
    "    inputs = {key: value.cuda() for key, value in inputs.items()}\n",
    "    inputs[\"generation_attention_mask\"] = inputs[\"generation_attention_mask\"].half()\n",
    "    outputs = model.generate(**inputs, max_new_tokens=max_length, \n",
    "                                do_sample=True,\n",
    "    # min_length=min_length, eos_token_id=tokenizer.eop_token_id, \n",
    "                            # num_beams=num_beams, length_penalty=length_penalty, no_repeat_ngram_size=no_repeat_ngram, temperature=temperature,\n",
    "                            top_p=0.95, \n",
    "                            top_k=5,\n",
    "                            )\n",
    "    output_tokens = outputs[0].tolist()                        \n",
    "    output = tokenizer.decode(output_tokens)\n",
    "    \n",
    "    return output, output_tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[50002,   602, 43233,  2291, 43658, 43400,   688, 18792, 26952,    30,\n",
      "         43668, 43360,  1309, 44162,   995,   613,  2421, 43361, 50009, 50000]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "[CLS] GLM-10b-chinese 10B [gMASK] <|endoftext|> <|startofpiece|> ,,97.7% [gMASK] [gMASK],\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "txt = 'GLM-10b-chinese 10B'\n",
    "\n",
    "\n",
    "t0 = time.time()\n",
    "ret, tokens = gen(txt, max_length=32)\n",
    "t1 = time.time()\n",
    "print(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] GLM-10b-chinese 10B [gMASK] <|endoftext|> <|startofpiece|> <|endofpiece|> [gMASK] <|endofpiece|> [gMASK] <|endofpiece|>,,,\n"
     ]
    }
   ],
   "source": [
    "print(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_in = tokenizer(txt).input_ids\n",
    "\n",
    "total_new_tokens_generated = len(tokens) - len(tokens_in)\n",
    "throughput = (total_new_tokens_generated) / (t1 - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens generated: 34\n",
      "Time: 0.9 seconds\n",
      "Tokens per second: 37.3\n",
      "Latency: 26.8 ms\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"Tokens generated: {total_new_tokens_generated}\n",
    "Time: {t1 - t0:.1f} seconds\n",
    "Tokens per second: {throughput:.1f}\n",
    "Latency: {1000 / throughput:.1f} ms\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "print(len(tokens_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "528"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = 'GLM-10b-chinese 10B'\n",
    "txt = \"\"\"[]\\n[]\\n[]\\n\\n[]\\n\\n\\n[]\\n\\n\\n[]\\n\\/\\n\\n[][]\\n\\n[]\\n[]:\\n[][]:\\n[]:\\n[][]:\\n###\\n[]:\\n[][]:\\n[]:\\n[][]:\\n### \\n[]:\\n[][]\"\"\"\n",
    "tokens_in = tokenizer(txt).input_ids\n",
    "len(tokens_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:31:59) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "822dc073326fbd4812d8e86d87412fd8a23e3469de4b9220769056828cfbb142"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
